---
layout: post
title: "DF Week6 - Optimisation I"
date: 2020-11-10
excerpt: "data fundamentals笔记"
tags: [学习笔记, data fundamentals, 2020, python]
feature: https://miro.medium.com/max/1400/1*gHamsYEMBoVIWbTbn3CQ-A.gif
comments: true
---

[reference: week_6_optimisation_i.pdf
](https://moodle.gla.ac.uk/pluginfile.php/1241382/mod_folder/content/0/week_6_optimisation_i.pdf?forcedownload=1)

infomation is filtered，，已筛选部分用得上的

* 目录
{:toc}

## Outline

Parameters, objective functions, classification of optimisation problems

you should know

* 在优化的背景下
  * **目标函数、约束函数和参数矢量是什么** what is objective func, constraint function, parameter vector
* how to play the piano
* **离散优化&连续优化**的区别 difference between discrete & continuous optimisation
* **凸优化 & 非凸优化** convex & nonconvex optimisation
  * 如何分辨
* **约束优化** constraint optimisation
  * **软约束 & 硬约束** soft & hard constraints
* **目标函数的主要性质** key properties of objective functions
  * 凸性 convexity
  * 连续性 continuity
* **优化用途**
  * 如何组成目标函数
* **最小二乘法** linear least squares
* **迭代优化** iterative optimisation
* **启发式优化原则** principles of heuristic optimisation
* **随即搜索的属性， 元启发式** the properties of random search, with the metaheuristics
  * 局部性 locality
  * 内存 memory
  * 温度 temperature
  * 总体 population

## Optimisation：优化

定义

![](/static/2020-11-10-01-25-47.png)

> **优化是调整事物使其更好的过程**。在计算机科学中，可以用算法自动实现优化。大量的问题可以被定义为优化，**而且有大量的算法可以有效地进行自动调整（优化）。因为它们可以在几个步骤中找到最好的调整**。
>
> 从这个意义上说，**优化就是搜索，优化算法利用问题空间的数学结构高效地搜索**

🍬 找到参数`θ*`（使目标函数输出最小化）过程 - 搜索

🍊 one algo torule them all: no special cases

* 优化算法允许我们将**标准算法应用于大量的问题**
  * 但不是每个特定问题都有特殊情况， 相反，**制定问题以用于通用算法 fomulate the problems to apply generic algo to solve them**。
  * 因此，应用优化算法之前，需要正式指定说明问题formally specified --- **详细指定说明问题，使得能用优化算法解决问题 specifying problems so that optimisation can tackle them**

## Objective Func & Parameters: 目标函数，参数(向量)

### 优化问题：组成（属性）

🍊 优化问题（使用优化算法解决问题）两个组成

![](/static/2020-11-10-01-35-50.png)

* parameter 参数
  * 可调整，**标量/向量/数组**
  * `θ`表示
  * 所在空间为，**参数空间`Θ`parameter space**
    * 包括所有可能参数配置
    * 类似`R^n`向量空间，但不一定就是
* objective function 目标函数
  * 将一个**参数映射到单一数字测量值**上的函数，<font color="red">用于评判参数配置（参数集）好坏 （针对好坏的量化衡量）</font>
  * `L（θ）`，输出 - **单个标量**
  * *或称，**损失函数**，成本函数，适应度函数，效用函数，能量面，所有这些概念大致相同 loss function, the cost function, fitness function, utility function, energy surface, all of which refer to (roughly) the same concept*
  * 目标函数就是设计变量的函数，是一个标量，（优化目的是最小化目标函数输出，使成本最小化）

🍬 除了参数，目标函数，大多数优化问题还有一个组成

![](/static/2020-11-10-01-45-09.png)

* constraints - 约束
  * 参数的限制 limitations on parameters
  * 定义了**参数空间可取范围，可行集/可行域 feasible set/region**

---

例子

![](/static/2020-11-10-01-44-59.png)
![](/static/2020-11-10-01-48-25.png)

### 优化算法：期望输出

🍊 优化算法的期望输出 The desired output of the optimisation algorithm

![](/static/2020-11-10-01-36-08.png)

* **最小化目标函数输出的参数配置** parameter configuration that minimises the objective function
* `θ* = arg minL(θ)` --- 目标函数argmin
  * `θ*` 参数配置：最小化目标函数输出的参数
  * `Θ` 参数空间：所有可能参数配置取值的集合，`R^N`

### Minimise difference: 如何得到目标函数

表现问题的形式

![](/static/2020-11-10-02-07-02.png)

* 目标函数（大多形式） - 参数影射到单一数字测量值
  * 测量**输出`y'`&参考`y`之间的距离**得到目标函数`L(θ)`
* `y'=f(x; θ)` 根据由一组参数`θ`控制的输入向量`x`（可能为测量值集合），产生输出`y'`
  * 使用**向量范数**，测量**输出`y'`&参考`y`之间的距离**
  * `L(θ) = ∥y' − y∥ = ∥f(x; θ) − y∥`
* <font color="red">目标函数输出 - 测量参数集好坏</font>

#### Approximation: 近似优化问题/算法

🍊 在近似优化问题中常见 approximation problems

![](/static/2020-11-10-02-19-19.png)

* 找到一个函数，逼近（近似）一组观测值
* `f(x; θ)`
  * `f`输出取决于 **输入`x`（向量）& 参数向量`θ`**
  * <font color="red">优化中，只调整参数`θ`，输入向量`x`固定【可能为测量值集合】</font>

🍊 例子

* 钢琴琴键`x` & 旋钮设置`θ`
  * 未优化 - 纯输入x, 影响生影`y'`
  * 优化 - 控制`θ`，输入`x`，影响声音`y'`

## Evaluating the Objective Func: 计算目标函数（参数集好坏）

计算目标函数成本高

![](/static/2020-11-10-02-40-59.png)

* 时间成本
* 可能涉及真实实验
* 危险性
* 花销成本 expensive

在任何情况下，计算目标函数都需要一定的计算能力，因此需要花费一定的时间。

* **这意味着一个好的优化算法可以在很少的查询(对目标函数的评估)下找到最优的参数配置【最小化目标函数输出**】
  * 需要**数学结构**
  * 在**没有任何结构的情况下**，<font color="red">最好的办法就是随机猜测参数配置，并在一些迭代次数之后选择成本最低的配置</font> randomly guess parameter configurations & choose the lowest cost configuration after some iterations【但不是典型计算途径】

## Discrete vs contiguous: 离散/连续优化问题

连续优化问题 continuous optimization

![](/static/2020-11-10-02-49-57.png)

* 参数在连续空间上`R^n`
* <font color="red">相对更简单</font>
  * 平滑性 smoothness
  * 连续性 continuity

连续优化问题 continuous optimization

![](/static/2020-11-10-02-50-05.png)

* 参数在连续空间上`R^n`

### 优化问题组成：properties

🍊 优化问题组成/属性 properties of optimisation

* parameters
  * 可调整，参数
* objective function
  * **测量参数集（配置）好坏**
  * **接收参数，返回单个标量**
* constraints
  * 参数可行集/域 feasible set/region

### Example：Throwing a stone

例如，如果我想优化我可以扔一块石头的距离，我可能可以调整投掷角度。

![](/static/2020-11-10-02-52-58.png)
![](/static/2020-11-10-02-53-17.png)

* 参数`θ` - 角度angle
* 目标函数
  * 依赖参数angle
* 如进行扔球，计算距离
  * 以水平方向**30度**左右的角度投球，将获得**最长的投掷距离**
  * 如果空气阻力比较大，那么抛物线应该是水平的

### 重点：向量空间的连续优化 & 近似优化算法（迭代）

Focus： continuous optimisation in real vector spaces

🍊 某些优化算法是迭代的，逐步生成近似值（近似优化算法）

* 本课关注，**迭代，近似优化算法**
* 其他直接算法，**最小二乘法 linear least squares**
  * <font color="red">在一个步骤中精确地找到最小值</font>

![](/static/2020-11-10-02-59-56.png)

* 连续向量空间`θ∈R^n=[θ1, θ2,...,θn]`
* 找到参数`θ*`（使目标函数输出最小化）过程 - 搜索
  * **在连续向量空间中找到`L(θ)`最小的点**

🍬 可能存在的问题

* 目标函数在向量空间中，也平滑&连续了（跟在连续向量空间中的参数一样）

## Geometric Median几何中间数：连续向量空间优化

高维空间的中间数 median

![](/static/2020-11-10-03-33-58.png)

* **某一向量：最小化数据集中其到所有其他向量距离（norm）之和** minimises the sum of distance to all vectors in the dataset
  * 最简单的优化例子？

### 最简单优化例子：高维空间中间数

![](/static/2020-11-10-03-52-31.png)

* 找到某点：最小化其到集合中其他点距离（范数，距离之和）
* 参数θ=[x,y,...]
  * 2D空间（连续）位置
* 目标函数
  * **参数点**与**其他点集合**的距离和
  * `L(θ)=sum ||θ - xi ||2`
  * 输出`θ*` - 某参数，最小化了距离之和

🍊 解法

![](/static/2020-11-10-03-53-10.png)
![](/static/2020-11-10-03-53-26.png)

* guess for θ
  * 随机初始条件，参数

### 例子2：evenly spaced

找到点布局layout of points，使得点**间隔均匀evenly spaced**（norm）

![](/static/2020-11-10-04-09-31.png)

* 需要优化整个点集合，（整个点集合和一个最优参数？）
* 参数`θ=[x1,y1,x2,y2]`
  * 2D点位置array（unpacked array因此, 仅需要一个参数点就可以实现）
* **损失函数/loss function**
  * 点之间的欧氏距离和目标距离之间的差值的平方和 the sum of squares of differences between the Euclidean pairwise distances between points and some target distance

🍊 解法

![](/static/2020-11-10-04-10-57.png)

* random initial guess for parameters
  * 64 2D points
  * 128-D θ（parameter space）

## Constraineed Optimisation: 约束优化

如果优化问题**参数有约束**，<font color="red">而且不仅仅是最小化目标函数输出</font>

![](/static/2020-11-10-04-15-57.png)

* **constrained optimisation** 约束优化问题
  * 例如，调节器，如果最优参数要求旋钮旋转到不可能值，那么该参数没有意义
* constraints 约束
  * **约束参数空间的每个维度** --- 限制了参数的可行集/域 limits the feasible set of the para

### 约束条件：equality & inequality constraint

![](/static/2020-11-10-04-20-53.png)

等式约束 equality constraint

* constraining parameters to a **surface** 将参数限制在单位球表面
  * represent a **tradeoff平衡**
* `c(θ) = ||θ||2 - 1` forces the para to lie on the surface of a unit sphere
* <font color="red">保持总值不变的情况下， trading off items平衡</font>

不等式约束 inequality constraint

* constraining parameters to a **volume** 将参数限制在box体积内
  * represent a **bounds on the values**
* `c(θ) = ||θ||inf - 10` forces the para to lie on within a box extending(-10, 10) around the origin
  * **可以看作，旋钮范围**
  * 限制最大值

### Common Constraint Types: Box constraint

![](/static/2020-11-10-04-41-20.png)
![](/static/2020-11-10-04-41-39.png)

### 硬约束&软约束&惩罚：Constraints & Penalties

**无约束优化**本身很少给出有用的答案。考虑翼型的例子。增加升力可以通过使翼型长度越来越长来实现。在某种程度上，这可能在物理上变得不可能建造。

可行集通常不是整个向量空间,有两种解决办法

![](/static/2020-11-10-04-47-38.png)
![](/static/2020-11-10-04-48-25.png)

* 约束优化 - 硬约束 hard
  * 使用内在支持**硬约束 hard constraints**的优化算法。对于某些类型的优化来说，这是直截了当的，但是对于一般的优化来说，就更加棘手了
  * 通常约束类型：**凸区域 convex region**或简单(超)矩形区域(一个box约束)
  * 优点
    * 保证解决方案满足约束条件。
    * 可以使用约束来加速优化。
  * 缺点
    * 可能比无约束优化效率低。
    * 可用于优化的算法更少。
    * 可能很难用优化器中的参数指定可行区域。
* **软约束 soft constraints**
  * <font color="red">对目标函数实施惩罚，以”阻止”违反约束的解决方案</font>。
  * 这是特别适当的，如果约束真的是软的(它可能并不重要，如果最大翼型长度是1.5米或1.6米，但它不能是10米)。
  * 在这种情况下，惩罚只是添加到目标函数中的术语。**优化器保持不变，但目标函数被修改。**
  * `L(θ ) = L(θ) + λ(θ)`
    * `λ(θ)`惩罚函数 penalty functions，当约束被破坏，惩罚值会变大
  * 优点
    * 任何优化器（算法）都可以使用
    * 明智处理软约束
  * 缺点
    * 可能不遵从重要的限制，特别是如果他们非常尖锐
    * 很难将约束作为惩罚
    * 在受限的空间区域不能有效搜索

## Relaxation of objective functions：松弛，优化问题的替代

**有效地解决离散优化和约束优化问题可能更加困难**;

![](/static/2020-11-10-04-57-57.png)

* 一些算法试图找到**相似的连续或无约束优化问题来代替**。
  * **这就是所谓的松弛，一个松弛版本的问题被解决了，而不是原来的难优化问题。**
  * 例如，有时一个问题中的约束可以被吸收到目标函数中，**将一个有约束的问题转化为一个无约束的问题**【惩罚函数】

### Penalisation：惩罚

我们使用的是梯度下降算法求出损失函数最小值（非约束优化），在添加惩罚项后，就相当于对损失函数做了约束。

> 惩罚函数，penalty function，用于**解决约束条件下的最优化问题**。
>
> 通过惩罚函数可以将**有约束的目标函数转化为无约束的目标函数**。

![](/static/2020-11-10-05-03-48.png)

* 增加目标函数以使解的某些其他性质最小化的项，通常是**近似约束最优问题**
* 通过惩罚函数实现：硬约束的松弛（转换成无约束）
  * 拉格朗日乘法

![](/static/2020-11-13-15-39-20.png)### Penalty function: 惩罚函数

![](/static/2020-11-10-05-04-47.png)
![](/static/2020-11-10-05-06-16.png)

惩罚函数

* 在目标函数中**加上一个不利于“坏解”的项**

🍊 扔石头例子

* 不仅控制角度，还控制力度
  * 力度有max limit -- **不等式约束，限制了力度参数的最大值（&最小值>0）**
* 目标函数解法
  * 约束算法
    * 不会搜索超过max力度的解
    * ![](/static/2020-11-10-05-11-34.png)
  * 改变目标函数 - 惩罚函数
    * 使过度繁重的投掷不可接受
    * ![](/static/2020-11-10-05-12-30.png)
    * ![](/static/2020-11-10-05-12-49.png)

## Properties of Objective Function: 凸目标函数组成（性质）

### Convexity, global and local minima：凸性，全局和局部最小值

目标函数可以有的其他性质？

### local minimum 局部最小值

![](/static/2020-11-10-05-20-13.png)

* 局部极小值是指目标函数在该点周围的每个方向上的任何点都增加？？？(即参数设置
  * any point where the objective functions increases in every direction around that point
  * **在这一点上参数的任何变化（任何参数）都会增加目标函数** Any change in the parameters at that point increases the objective function

### 凸目标函数 & 凸性：convex convexity

![](/static/2020-11-10-05-22-55.png)
![](/static/2020-11-10-05-24-41.png)
![](/static/2020-11-10-05-24-54.png)

有**一个，全局最小值**的目标函数

* 抛物线parabola
  * 最小 & 一个

凸性

* 找到任意最小值 == 于找到**全局最小值**
  * **保证最优参数，优化问题最优解**
* 在凸问题中，如果我们找到一个最小值，我们就可以停止 or 如果我们可以证明没有最小值，我们也可以停止搜索

### 凸优化问题 & （凸/非凸）解法：Convex Optimisation

凸优化问题

![](/static/2020-11-10-05-29-39.png)

* **目标函数是凸的（有一个全局最小值）**
* 任意**约束形成搜索空间的凸部分**

🍊 以下**凸优化问题解法 - 高效**（就算变量有万以上）

* 约束条件和目标函数是线性的
  * 解法：(**线性规划**)
* 二次目标函数和线性约束
  * (**二次规划**)
* 或者一些特殊情况
  * (**半二次规划，二次约束二次规划**)

这些都是不可思议的强大算法，用于解决这些特定类型的优化问题

🍬 **非凸问题需要使用迭代方法**(尽管确实存在用凸问题逼近非凸问题的方法)。

## 非（离散） & 连续目标函数： Continuous Objective Function

连续性 continuity

连续目标函数

![](/static/2020-11-10-05-40-26.png)

* 如果对于一些非常小的参数`θ`调整，目标函数都有一个任意小变化
* 这意味着，**如果我们在参数空间的移动速度足够慢（参数θ改变慢），不会突然出现值跳跃**
* 连续性使得连续优化比离散优化更容易,
  * continuous optimisation easier than discrete optimisation
* 连续性和可微分性使得连续优化更加强大
  * continuous and differentiable

非连续目标函数（离散）

![](/static/2020-11-10-05-42-26.png)

* 如果一个函数是不连续的，局部搜索方法不能保证收敛到一个解。
* **对不连续的目标函数进行优化通常比对连续函数进行优化困难得多**
  * 这是因为对参数的任何调整都可能使目标函数发生**任意变化** --- **无法预测**参数改变时，目标函数的输出

## 直接凸优化-最小二乘法：Direct convex optimisation:linear least squares

凸优化问题解法？

![](/static/2020-11-10-05-48-08.png)

* 最小二乘法，解决上面形式的目标函数
  * 求`x`目标函数输出，就是解何时L2范数平方最小
* 全局最小值 - 可直接获得

## 直线拟合：line fitting

最简单线性回归例子 - 优化线性回归

![](/static/2020-11-10-05-59-03.png)
![](/static/2020-11-10-05-59-12.png)
![](/static/2020-11-10-05-59-19.png)

* `y=mx+c`
  * 求`m`斜率&`c`偏移值。满足`（x,y）`的距离平方最小化
* 参数
  * `θ=[m,c]`
* 用SVD pseudo-inverse解/优化线性回归例子

## (非凸?)迭代优化：Iterative Optimisation

![](/static/2020-11-10-06-00-59.png)

迭代优化包括在参数空间中制定一系列步骤。

* 有一个**当前的参数向量(或者它们的集合)在每次迭代中被调整** current parameter vector (or collection of them) which is adjusted at each iteration
* 希望减少目标函数输出，**直到满足某些终止标准后优化终止** until optimisation terminates after some termination criteria have been met

迭代优化算法

1. 选择起点`x_0`
2. while 目标函数改变
   1. 调整参数
   2. 计算目标函数输出值
   3. 如果输出比当前的更好，记录下来
3. 返回最优参数

### 凸优化 vs 非凸优化

![](/static/2020-11-13-15-40-51.png)

🍊 凸优化重要性

* 凸优化的重要在于它是一个相对而言被嚼烂的数据模型，对凸优化的问题我们在基础数学上面已经有了很多解决方法，例如可以将凸优化问题Lagerange做对偶化，然后用Newton、梯度下降算法求解等等。

## 常规搜索 - 网格搜索：Regular search: grid search

![](/static/2020-11-10-06-05-24.png)
![](/static/2020-11-10-06-16-18.png)

对于多维问题，网格搜索是一种简单但低效的优化算法。

* 参数空间的采样方法是对每个维上的可行集进行等分，通常每个维上都有固定数量的分割。

在这个网格的`θ`上对目标函数进行计算，并跟踪到目前为止发现的最低损失。

* 这是简单的，可以用于**一维优化问题**
* 它有时被用来优化机器学习问题的超参数，其中目标函数可能是复杂的，但找到绝对最小并不是必要的

🍊 网格搜索受到维数灾难的影响，但是经常是令人尴尬的并行，因为它评估的超参数设置通常是相互独立的。

* Grid search suffers from the curse of dimensionality, but is often embarrassingly parallel because the hyperparameter settings it evaluates are typically independent of each other.

### 维度诅咒：revenge of the curse of dimensionality

即使在相对较小的参数空间中，并且目标函数已知是平滑的，它也不能很好地伸缩。

![](/static/2020-11-10-06-18-03.png)
![](/static/2020-11-10-06-19-02.png)

* 简单地将每个维度划分为若干个点(也许是8个) ，然后在这些点组成的网格上尝试每个组合，选择最小的结果
* **虽然在1D (只检查8个点)和2D (只检查64个点)中这是好的**，
  * 但是如果你有一个100维的参数空间，它就完全崩溃了

### 深度：Density of Grid Search

![](/static/2020-11-10-06-20-04.png)
![](/static/2020-11-10-06-21-13.png)
![](/static/2020-11-10-06-22-34.png)

* 如果目标函数不是很平滑，那么就需要一个更加密集的网格来捕捉任何极小值
* 真正的优化问题可能有数百、数千甚至数十亿个参数(在大型机器学习问题中)。网格搜索和类似方案在参数空间的维数上是指数形式的
* 优点
  * 适用于任何连续参数空间。
  * 不需要知道目标函数。
  * 简单实现
* 缺点
  * 效率非常低
  * 必须提前指定搜索空间界限。
  * 高度偏向于在空间的“早期角落”附近寻找东西。【curse of dimentionality】
  * 在很大程度上取决于选择的区域数量
  * 很难调整，所以极小值不会被完全错过。

### 超参数：Hyperparameters

网格搜索取决于搜索范围和网格划分的间隔。大多数优化算法具有类似的特性，可以进行调整。

这些影响优化算法找到解决方案的方式的属性称为**超参数**。

![](/static/2020-11-10-06-27-00.png)

* **它们不是目标函数的参数，但它们确实影响到所得到的结果**
* 一个完美的目标算法没有超参数——解决方案不应该依赖于如何找到它。
  * 但实际上，所有有用的目标算法都有一些超参数，这些超参数会影响它们的性能。更少的超参数通常是更好的，因为目标算法工作起来不那么麻烦

## 随机搜索: Simple stochastic: random search

最简单的这样的算法是随机搜索，除了我们可以从参数空间中提取随机样本之外，它不做任何假设。

![](/static/2020-11-10-06-59-46.png)

🍊 步骤

* 猜测随机参数θ
* 计算目标函数输出
* 如每次L(θ)<L(θ*),则更新最优解

终止条件有许多可能性，

* 例如在最佳损失的最后一次更改之后，在一定数量的迭代之后停止。

![](/static/2020-11-10-07-01-59.png)
![](/static/2020-11-10-07-01-46.png)

优点

* 随机搜索不能陷入局部极小值，因为它没有使用局部结构来指导搜索
* 不需要知道目标函数的结构——甚至不需要知道拓扑
* 非常简单的实现
* 几乎总是比网格搜索好

缺点

* 极其低效，通常只有在**没有其他数学结构可以利用的情况下才适用**
* 必须可以从参数空间随机采样(但通常不是问题)
* 随着时间的推移，结果并不一定会变得更好。最好的结果可能会在第一步或一百万步中找到
* 没有办法预测优化将如何进行

### bogosort：joke sorting algo

![](/static/2020-11-10-07-03-09.png)

## 元启发式算法-改进随机搜查:Metaheuristics

![](/static/2020-11-10-07-04-01.png)

一系列标准元启发式算法，用于改进random search

* Locality
  * 它利用了目标函数对于**相似的参数配置可能具有相似的值**这一事实。
  * 假定目标函数为连续的
* Temperature
  * 它可以在优化过程中**改变参数空间的移动速度**
  * 假设存在局部最优解
* Population
  * 它可以跟踪**多个同时进行的参数配置，并在它们之间进行选择/混合**
* Memory
  * 它可以记录过去的好的或坏的步骤（目标函数输出），避免/再次访问它们

### 局部搜索：Locality

局部搜索（LocalSearch-LS）是区别于传统全局精确搜索的新兴的求解思路，它广泛用于求解NP难题

局部搜索是指对**解决方案进行增量更改**的一类算法

![](/static/2020-11-10-07-13-18.png)

* 当目标函数具有一定的连续性时，比随机搜索或网格搜索更有效
* 然而，他们可能会陷入局部极小值，而无法达到全局极小值
* 它们通常只用于非凸优化问题，这可能是个问题
  * 这意味着**最优化的输出取决于初始条件**。结果可能会发现从一个位置开始的一个局部最小值，和从另一个起始参数集开始的另一个局部最小值【不同局部最小值】

🍊 局部搜索可以认为是通过参数空间形成的轨迹(一条路径) ，从而有望从高损耗走向低损耗

#### 爬山法-局部搜索：Hill climbing local search

爬山是对随机搜索的一种修正，它假定参数空间的某种拓扑结构，因此存在一个有意义的参数向量邻域的概念，我们可以对它进行渐进式的改变。

爬山是局部搜索的一种形式，它不是从参数空间中随机抽取样本，而是在当前最佳参数向量附近随机抽取样本。它进行增量调整，只有在损失得到改善的情况下，才保持向邻国的过渡

![](/static/2020-11-10-07-16-49.png)
![](/static/2020-11-10-07-17-13.png)
![](/static/2020-11-10-07-17-25.png)

简单的爬山一次只调整一个参数矢量元素，检查每个“方向”

* 如果情况有所改善，就转身向前迈一步。随机爬山对参数向量进行随机调整，然后根据结果是否有所改进而决定是否接受或拒绝步长。

爬山这个名字来源于这样一个事实: 这个算法随机地四处游荡，只采取上坡(或下坡，为了最小化)的步骤。

因为爬山是一种局部搜索算法，所以很容易陷入局部极小值。

* 基本的爬山运动对极小地点没有防御作用，如果存在极小地点，很容易陷入糟糕的解决方案。简单的爬山也可能会卡在山脊后面，所有形式的爬山都要与失去功能变化缓慢的高原抗争。

---

同样，这个基本算法可以通过多种方式进行调整

![](/static/2020-11-10-07-18-07.png)

适应性局部搜索，邻域的大小可以调整(例如，如果迭代没有改进，增加随机步骤的大小)多次重新启动，通过对随机初始猜测多次运行该过程来尝试避免陷入局部极小。这是另一种启发式算法——一种应用于搜索算法本身的启发式算法

### Temperature温度-Simulated annealing: temperature schedules and minima escaping 模拟退火: 温度时间表和最小逃逸

![](/static/2020-11-10-08-16-47.png)
![](/static/2020-11-10-08-17-12.png)
![](/static/2020-11-10-08-17-47.png)

### Population

![](/static/2020-11-10-08-19-53.png)

### 交叉规则/遗传算法：crossover rules

![](/static/2020-11-10-08-21-05.png)

### 遗传算法-种群搜索：Genetic algo：population search

![](/static/2020-11-10-08-22-28.png)

### Memory

我们看到的优化算法是**无记忆的memoryless**。他们调查一部分解决方案空间，检查损失，然后继续前进。

* **他们可能会一遍又一遍地检查相同或非常相似的解决方案**
  * 这种低效率可以通过使用某种形式的内存来缓解，
* **优化器会记住参数空间的“好”和“坏”位，并使用这些内存做出决策**
  * 特别是，我们要记住解空间中的**良好路径paths in solution space.**

### Memory + Population

#### 蚁群优化算法：Ant colony optimisation

![](/static/2020-11-10-08-27-03.png)
![](/static/2020-11-10-08-27-58.png)
![](/static/2020-11-10-08-27-44.png)

蚂蚁群体优化结合了记忆和群体启发法，它使用激进的思想来优化问题

* 蚁群算法特别适合于路径搜索path和路径搜索算法route，其中信息素路径的存储结构对应于解的结构

![](/static/2020-11-10-08-28-34.png)

## 优化质量: Quality of Optimisation

### 收敛：Convergence

![](/static/2020-11-10-08-30-25.png)

一个优化算法被称为收敛到一个解决方案

* 在凸优化中
  * 这意味着已经找到了**全局最小值**，问题得到了解决
* 在非凸优化中
  * 这意味着找到了算法无法逃避的**局部最小值**

🍊

* 一个好的**优化算法收敛速度很快**
  * 这意味着目标函数的下降应该是陡峭的，因此每次迭代都会产生很大的差异
* 一个糟糕的优化算法**根本不收敛**(它可能永远徘徊，或者发散到无穷远)
* **许多优化算法只在一定条件下收敛**
  * 收敛取决于<font color="red">优化的初始条件(非凸优化算法?)</font>

### 保证收敛：Guarantees of convergence

![](/static/2020-11-10-08-34-39.png)

* **一些优化算法在解存在的情况下保证收敛**
* 而另一些算法(像大多数启发式优化算法一样)**即使问题有解也不保证收敛**
  * 例如，一个随机搜索可能永远徘徊在可能性的空间，从来没有找到具体的配置，最大限度地减少(甚至减少)损失

🍊 对于迭代解，**目标函数值与迭代的关系图是诊断收敛问题的有用工具**

![](/static/2020-11-10-08-40-14.png)

* 理想情况下，损失（目标函数值）应该尽可能快地减少

### 优化调整：Tuning Optimisation

只要我们能写出一个目标函数，优**化就可以把特定的问题转化成通用算法可以解决的问题**。

* 然而，优化算法有超参数，这些**超参数会影响搜索最优值的方式**
  * 有效地使用优化器需要调整这些超参数

🍊 使用正确算法

![](/static/2020-11-10-08-55-07.png)

🍊 会出什么问题

![](/static/2020-11-10-08-57-18.png)
![](/static/2020-11-10-08-59-03.png)

### 困境：Getting Stuck

![](/static/2020-11-10-08-59-40.png)
![](/static/2020-11-10-09-00-01.png)