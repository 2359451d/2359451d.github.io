---
layout: post
title: "IS Week 7 - Analysis Techniques and Statistics:分析方式 & 统计"
date: 2020-11-30
excerpt: "interactive system 笔记， lectures11-12. focus on analysis techniques for quantitative data, including how to select appropriate statistical methods and present results from lab studies and surveys.注重定量数据的分析技术，包括如何选择适当的统计方法和提出实验室研究和调查的结果；"
tags: [学习笔记, interactive system, 2020]
feature: https://miro.medium.com/max/1400/1*gHamsYEMBoVIWbTbn3CQ-A.gif
comments: true
---

* 目录
{:toc}

## 分析用户研究的数据：Analysing Data from User Studies

![](/static/2020-12-01-15-56-10.png)

* 提供 "描述性统计数字 "是最起码的
  * 平均、分布、标准差
* 以假设检验的方式提出主张，推断因果关系
  * 你有没有证明你的产品比现有的方法 "更好"

## 衡量尺度（4种基本数据类型）：Measurement Scales

![](/static/2020-12-01-15-55-57.png)

* 从每次测量可能进行的计算类型来看

---

![](/static/2020-12-01-16-00-23.png)
![](/static/2020-12-01-17-08-17.png)
![](/static/2020-12-01-21-18-58.png)
![](/static/2020-12-01-21-15-04.png)
![](/static/2020-12-01-21-16-04.png)
![](/static/2020-12-01-21-16-55.png)
![](/static/2020-12-01-21-20-39.png)
![](/static/2020-12-01-21-18-15.png)

* **定类变量** Nominal/Category
  * 标签或名称
    * 这些可以是数字，但不能用它们来做计算，比如随机生成的ID
  * 只是分类：如男，女
* **定序变量** Ordinal
  * 可以把数值进行排序，但不是等距的
    * 如：喜欢的电影列表
  * 可以做>或<比较，但计算均值无效
  * 可以排序，不能加减
* **定距变量** Interval
  * 相邻值之间的距离相等，没有绝对零点？。
  * **可以计算平均值**
  * 可以加减
  * 例如：摄氏度表
    * 可以取一周气温的平均值，但严格来说20℃并不是10°的 "两倍热"
    * 当温度为`0`时，并不是表示没温度，因此为interval data
  * **Likert量表**
    * 有时会被视为Ordinal或Interval。知道用哪种方法计算平均值很重要。如果选项间距相等，并且以中性值为中心，则可以处理为区间
* **定比变量** Ratio
  * 有绝对0值（true zero，如重量，长度，为`0`时就是没有该变量）
  * 支持多种计算
    * 加法
    * 除法
    * 平均值
    * 标准差
  * 事件的时间，距离，个数

🍊 Ratio & Interval区别 - **存不存在 absolute 0**

## 计算和测量: Evaluation and Measurements

![](/static/2020-12-01-22-29-38.png)

* 在做任何事情之前，你需要做好计划，并通过收集正确的数据来衡量正确的因变量。
* 数据类型
  * 从定性和定量的角度思考数据的问题
  * 从连续到离散的谱系中思考定量的数据

## 描述性统计量：Descriptive Statistics

![](/static/2020-12-01-22-31-00.png)

* 中心倾向的测量。
  * 平均数、中位数和Mode
* **平均数**的计算很简单，但也提供了很少的（或潜在的误导性）信息
  * 通常只有当数据呈正态分布时才有用
* 中位数可能与平均数有显著差异，这可以洞察数据的 "形状"
* 标准差描述了数据的分布情况
  * 估计平均值的平均差异
* 绘制分布图能告诉你更多的东西，而不是简单的数值

## 标准差&正态分布：Standard Deviation & Normal Distribution

![](/static/2020-12-01-22-47-25.png)

* 经验法则 Empirical Rule
  * 有多少个样本值在平均值的x个标准差内
* Z-score z分数（标准分数normal score）
  * 平均值的标准偏差数（正态分布情况下?）

## 标准差-评估数据:Standard Deviation for Evaluation Data

![](/static/2020-12-01-23-51-06.png)

* 涉及参与者的原数据，通常不是正态分布的

## 中心极限定理：Central Limit Theorem

![](/static/2020-12-01-23-53-31.png)
![](/static/2020-12-02-00-11-43.png)

* 当样本量接近无穷大时（但通常说>30时，对于区间数据甚至更小），无论母体人口如何分布，**【样本均值】的分布将遵循正态分布**
* 甚至适用于二进制数据

🍊 中心极限定理意味着即使**数据分布不是正态的**，从中**抽取的样本均值的分布**也是正态的

* <font color="red">为了使中心极限定理能够起作用，我们必须能够计算出样本的平均值</font>

### 中心极限定理-意义：Implications

![](/static/2020-12-02-00-14-20.png)

* <font color="red">许多统计假设检验（如t检验）都假定数据呈正态分布</font>
  * 如果数据（本身）**非正态分布**（如偏斜），**假设检验是否仍适用**？
* 如果样本量足够大，CLT中心极限定理说明，样本均值的分布近似于正态分布
  * 所以，我们可以用这些**假设检验**

## 标准误差：Standard Error

![](/static/2020-12-02-00-18-46.png)
![](/static/2020-12-02-00-19-56.png)

![](/static/2020-12-02-00-22-06.png)
![](/static/2020-12-02-00-23-16.png)
![](/static/2020-12-02-00-24-05.png)
![](/static/2020-12-02-00-25-46.png)

---

![](/static/2020-12-02-00-27-44.png)

* 通常不会进行多次实验/使用多种样本
  * 对于平均值未知的总体，如何获取样本的均值误差？

🍊 例子： 样本标准差/sqrt（样本大小）

![](/static/2020-12-02-00-31-18.png)

## 假设检验：Hypothesis Testing

> 假设检验采用了**反证法，即先提出假设**，再通过适当的统计学方法**证明这个假设基本不可能是真的**。（说“基本”是因为统计得出的结果来自于随机样本，**结论不可能是绝对的**，所以我们只能根据概率上的一些依据进行相关的判断。）

![](/static/2020-12-02-00-48-46.png)

* **零假设 Null Hypothesis**
  * 拒绝零假设
  * **是试验者想收集证据予以反对的假设，也称为原假设**
* 为什么要这样做研究？
  * 很难用科学的方法来证明什么
  * 更容易反驳
* 考虑以下两个说法
  * 每个软件项目都有错误
  * 软件项目永远不会有错误

![](/static/2020-12-02-00-51-23.png)

* 可能是在寻找充分的证据（而不是确切的证据）
* 统计学检验在检验什么？**两个样本来自同一分布的可能性有多大**？
* 还感兴趣的是
  * **我们有多大信心它们是不同的**？
  * 它们相差多少？effect size差异大小

---

![](/static/2020-12-02-00-53-48.png)
![](/static/2020-12-02-00-58-16.png)

🍊 请看一个比较鼠标和触控板的例子

* **零假设**
  * 用户在使用这两种输入设备进行对象选择任务时的**表现没有差异**
* **如果我们拒绝零假设**，
  * 我们就可以对数据进行分析，提出结果，**论证差异发生在哪里**，以及这样做对交互作用可能有什么好处

### 常用术语

显著性水平（level of significance）：当零假设为真时，错误拒绝零假设的临界概率，**即犯第一类错误的最大概率，用`α`表示。**

* 例如：在5%的显著性水平下（α=0.05, p<0.05，此时原假设为真），样本数据拒绝原假设（**错误地拒绝了，因此犯了Type1错误**，<font color="red">此时犯错概率就是p-value</font>）
* 给定target`α`显著性水平之后，等于给定拒绝域
  * 如果`p<α`, 即样本落在拒绝域内，则拒绝原假设

临界值（critical value）：与**检验统计量的具体值进行比较的值**。

* 是在概率密度分布图上的分位数。这个分位数在实际计算中比较麻烦，它需要对数据分布的密度函数积分来获得。
* 根据显著性水平`α`计算得来？
* 如果**检验统计量<临界值**，接受零假设
* <font color="red">这两个不足之处在于，无法像pvalue一样给出概率</font>

### p-value大小 & 说明

`p<0.01`

* 零假设有`99%`把握发生

`p<0.05 & p>0.01`

* 零假设有`95%`几率发生

![](/static/2020-12-02-20-03-16.png)

🍊 p-value

* 零假设为真时所得到的样本观察结果或获得更极端结果的概率
  * The p-value is the probability of the test statistic being at least as extreme as the one observed given that the null hypothesis is true.
* **p值是当原假设为真时，错误拒绝原假设的实际概率**
* 给定target`α`显著性水平之后，等于给定拒绝域
  * 如果`p<α`, 即样本落在拒绝域内，则拒绝原假设。如果原假设为真，那么此时犯TYPE I错误（假设为真时错误拒绝的概率）的几率为`p`【即，如果原假设为真，通过抽样获得这样的样本数据可能性只有`p`】

### 假设检验的步骤

1. 定义总体
2. 确定零假设
3. 选择检验统计量（**确定假设检验的种类，不同检验统计量的意义不同**）
4. 为p-value选定target-`α(显著性水平)`
5. 从总体进行抽样，得到一定数据
6. 根据样本数据计算检验统计量的具体值
7. 根据检验统计量的抽样分布 & p-value，确定拒绝域

## （独立）t检验和配对t检验：t-test & paired t-test

🍊 t检验 - 其中一种假设检验

![](/static/2020-12-02-00-59-41.png)

* 1908年，在吉尼斯工作的化学家William Gosset（"学生"）开发了t检验，定量测量啤酒的质量。
* 假设
  * **数据遵循正态分布**
  * 从区间interval/比率ratio数据中提取数据
* 可在依赖样本（dependent samples & within subjects）数据集上用配对t检验完成，
* 或独立数据集（independent samples & between subjects）上用独立样本T检测完成

---

🍊 T检验 - 判断样本均值之间是否存在差异（**仅能对比两组数据的差异，超过两组可能选择方差检验**）

* 事先**不知道总体方差（均值，标准差）**。根据小样本来**估计呈正态分布且方差未知的总体的均值**
* 如果总体**不服从正态分布**，最好不要考虑T检验
* 如果总体**服从正态分布**，样本量无要求

---

🍊 T-value（T检验统计量）计算

![](/static/2020-12-02-22-04-11.png)

### T检验分类

配对T检验 paired sample T-test

* compares means from the same group at different times
* 用两个配对样本中各对观测值的差值均数和假设的差值进行比较
* **本质是先计算成对观测值之间的差异的均值，之后执行单样本t检验**
* <font color="red">用于配对定量数据之间的差异对比关系.例如在两种背景情况下(有广告和无广告);样本的购买意愿是否有着明显的差异性【组内，对同样消费者进行不同条件下同样的实现，**依赖样本**】</font>

独立样本T检测 Independent samples t-test

* compares mean for two groups

单样本T检验 One Sample T-test

* tests the mean of a single group against a known mean
* 用样本均值和总体均值进行比较，来检验样本与总体之间的差异性

### T分布：T-Distribution

![](/static/2020-12-02-00-41-04.png)

* 当样本分布，均值，标准差未知时（更标准来说是方差未知）
  * T分布，T分数

🍊 用于根据小样本来**估计呈正态分布且方差未知的总体的均值**。如果总体方差已知（例如在样本数量足够多时），则应该用正态分布（z分数）来估计总体均值

### T检验 & 方差分析（ANOVA检验）区别与选择

![](/static/2020-12-02-19-34-13.png)

* 特点：数据最好满足**正态分布时**考虑，
  * 其中如果t检验不满足正态分布，要求样本量>30（**一般不考虑此例，不服从直接不考虑**）
  * 否则，考虑**非参数检验，对样本分布无特定要求**
* 目的：都是检测多个样本之间**是否具有显著性差异**
  * 方差分析 - 2组及以上
  * t检验 - 仅2组
  * <font color="red">如果样本刚好为2组，样本较少（<100）时使用T检验，反之使用ANOVA方差分析</font>
* 数据要求
  * interval/ratio

## 非参数检验

非参数检验用于研究定类数据与定量数据之间的关系情况。例如研究人员想知道不同性别学生的购买意愿是否有显著差异。**如果购买意愿呈现出正态性，则建议使用方差分析（多组），如果购买意愿没有呈现出正态性特质，此时建议可使用非参数检验。**

* 如果X的组别**为两组**，比如上表中男和女共两组，则应该使用MannWhitney/Wilcoxon统计量（秩和统计），
  * 独立样本 - MannWhitney
  * 依赖样本 - Wilcoxon
* 如果组别**超过两组**，则应该使用Kruskal-Wallis/Friedman统计量结果
  * 独立样本 - Kruskal-Wallis
  * 依赖样本 - Friedman

## 独立 & 依赖样本

独立样本 - different subjects

* between group

依赖样本 - repeated measures on the same subjects

* within group
* 关键字：paired, before&after, people&employee

## 非参数检验-依赖样本：Friedman & Wilcoxon Tests

Friedman和Wilcoxon检验

![](/static/2020-12-02-19-14-47.png)

* Friedman 弗里德曼检验
  * 参与者对n种不同葡萄酒的质量进行评价
  * **零假设**。两款酒之间没有差别
  * 目的：**用于检测多个(相关)样本是否具有显著性差异的统计检验**
  * 依赖样本
  * `>`2组
* Wilcoxon 检验（秩和检验） 和Mann-Whitney 类似
  * 用于**配对（正好2组）**比较，可以提供描述哪些葡萄酒被评为明显优于其他葡萄酒的结果
  * sign test?符号检验?符号比较：更好还是更差？
  * 依赖样本
  * 正好2组
* 用于**相关样本的差异检验（组内 within subjects**）
* 用于**非正态分布的序数ordinal数据或区间interval数据**

### 扩展：Friedman检验

属于**非参数检验（不要求样本服从任何特定分布，如正态分布）**

* 数据来自ordinal ,interval(如likert scale)
  * 关键步骤 - 对原数据进行rank
* 数据来自一个单独群体，至少3个不同情况的测量
  * 如一个rate，3种以上的酒品的rate
* 样本随机抽样获取
  * 所有pairs都独立，不会互相影响

🍊 目的：用于检测多个(相关)样本是否具有显著性差异

* 主要是考虑到样本不服从任何特定分布的情况下

🍬 常见应用

* <font color="red">对于相同DV在不同IV条件下的多次测量。且数据可能不服从任何分布</font>
* 因变量 Dependent Variable
  * continuous scale，通常可能不为正态分布的
* 自变量 Independent Variable
  * 不同分类，Time/Condition

🍬 通常步骤

* 对于原数据，每个DV的不同IV样本进行从低到高的rank（秩）化
  * 如，询问user likert风格的问题（喜欢->不喜欢）给出orinal数值，数值越低rank越前（如越喜欢，rank1， A-rank1 & D-rank4）
* 计算每个IV字段的rank总和

🍊 例子

![](/static/2020-12-02-18-39-27.png)
![](/static/2020-12-02-18-41-15.png)
![](/static/2020-12-02-18-41-47.png)

计算Friedman检验需要的检验统计量 test statistics

* `n` 实验者数量
  * 12
* `k`治疗数量
  * 3
* `r`每个字段的rank总和
  * 32，27，13

![](/static/2020-12-02-18-49-13.png)

### 扩展：Wilcoxon检验

一般即意味使用 wilcoxon符号秩和检验 - signed test

* 注意：样本为**paired（正好2组） & 依赖样本**时使用
* 一般适用于样本**非正态分布**时，
  * 正态分布时正确率没有T检测高
* 如样本为独立样本，paired，使用 MannWhitney检验

🍊 步骤

1.计算组间差异
![](/static/2020-12-02-21-03-56.png)

2.根据差异，作为秩，进行升序排序（从小到大）
![](/static/2020-12-02-21-04-11.png)

* 差异为负时，`*-1`再作为秩排序

3.忽略差异为`0`的情况，根据差异的正负为秩加上符号`+/-`
![](/static/2020-12-02-21-05-01.png)

3.分别计算检验统计量`W+/W-`的值，即正的秩，&负的秩的值

* 验证`W+/W-`的值，其中`W+ + W- = n(n+1)/2`

4.`W`检验统计量用于跟临界值比较？（或者从中提取p-value与显著性水平α比较）

## 非参数检验-独立样本：Mann-Whitney & Kruskall-Wallis Tests

![](/static/2020-12-02-01-06-10.png)

* Kruskall-Wallis就像Friedman一样，
  * **但用于独立样本（组间between subjects）**
  * `>`2组
* Mann-Whitney与Wilcoxon类似，
  * **但适用于独立样本**
  * 正好2组
  * 同样的情况，参与者对n种葡萄酒进行评分
* 零假设：参与者无法辨别葡萄酒之间的区别（即葡萄酒之间没有差别）
  * Kruskall-Wallis 检验将告诉我们参与者之间是否存在差异（例如，通过将参与者按品酒经验进行分组），
  * Mann-Whitney 将提供**成对（正好2组）**比较，以比较每组的情况

## 如何展示统计量结果&p-value&检验统计量 test statistic & 效应量  effect size：How to Present Statistical Results

![](/static/2020-12-02-01-15-00.png)

* 每个检验都会产生一个**p-value（样本来自同一分布的概率）** & **检验统计量 test statistics（用于假设检验计算的统计量）**
  * 可以为p-value选一个目标（显著性水平`α`）；
  * **一般`p<0.05`表示有统计学意义**
* 每个测试检验的检验统计量都有不同的解释
* 大多数测试也会以**效应量（effect size），差异大小**来呈现
  * 样本间差异或相关程度的量化指标。效应量越大，两组平均数离得越远，差异越大
  * 该值范围在0到1之间，描述效果的 "可见性"

🍊 p-value

* 零假设为真时所得到的样本观察结果或获得更极端结果的概率
  * The p-value is the probability of the test statistic being at least as extreme as the one observed given that the null hypothesis is true.
* **p值是当原假设为真时，错误拒绝原假设的实际概率**
* 给定target`α`显著性水平之后，等于给定拒绝域
  * 如果`p<α`, 即样本落在拒绝域内，则拒绝原假设。如果原假设为真，此时犯TYPEI错误的几率为`p`【即，如果原假设为真，通过抽样获得这样的样本数据可能性只有`p`】

## 假设检验的两类错误: Errors in Statistical Testing

![](/static/2020-12-02-01-20-13.png)
![](/static/2020-12-02-01-50-59.png)

* 决策：`p<0.05`时拒绝了零假设
  * null is true - False Positive
  * **零假设为真**时 - 错误地拒绝了零假设（此时犯TYPEI错误概率为`p`，即抽样的到的样本数据可能性只有`p`）
* 决策：`p>0.05`接受了零假设
  * null is false - false negative
  * **零假设为假**时 - 错误地接受了零假设

---

一般来说，在样本量确定的情况下，任何决策无法同时避免这两类错误的发生，

* 即在减少第一类错误发生的同时，会增大第二类错误发生的几率，
* 或者在减少第二类错误发生的同时，会增大第一类错误发生的几率

🍊 在大多数情况下，人们会控制第一类错误TypeI发生的概率

* **事先给定显著性水平α的值**来控制第一类错误发生的概率，常用的 α 值有 0.01，0.05，0.1
  * p target?
* 如果犯第一类错误的成本不高，那么可以选择较大的α值；如果犯第一类错误的成本很高，则选择较小的α值

🍬 人们将**只控制第一类错误的假设检验**称为**显著性检验**，许多假设检验的应用都属于这一类型

## 非参数检验：秩Rank

Rank - 秩

![](/static/2020-12-02-19-07-54.png)

* 非参数检验（不要求数据遵从任何特定分布，一般就是分布未知）中常用概念
* **秩就是数据按照升序排列（从小到大）后，每个观测值的位置**

🍊 利用秩的大小，进行推断，**避免了不知道总体分布的困难**