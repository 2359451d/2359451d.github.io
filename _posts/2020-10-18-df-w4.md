---
layout: post
title: "DF Week4 - Computational Linear Algebra I"
date: 2020-10-18
excerpt: "data fundamentals笔记"
tags: [学习笔记, data fundamentals, 2020, python]
feature: https://miro.medium.com/max/1400/1*gHamsYEMBoVIWbTbn3CQ-A.gif
comments: true
---

[reference: week_4_Computational Linear Algebra I.html
](https://moodle.gla.ac.uk/pluginfile.php/1241379/mod_folder/content/0/week_4_matrices_i.pdf?forcedownload=1)

infomation is filtered，，已筛选部分用得上的

* 目录
{:toc}

## Outline

you should know

* **vector & vector space**
  * standard operations on vectors: add & multiplication
* **norm 范式**
  * how it can be used to measure vectors 如何使用norm测量vector
* **inner product 向量内积**
  * 向量内积如何产生向量的几何形
* **mathematical vectors** map onto **numerical arrays** 数学矢量如何映射到数字数组上
* 不同的**p规范(p-norm**)及其用法
* 向量表示的重要计算用途
* how to **characterise vector data with a mean vector and a covariance matrix** 如何用平均矢量和协方差矩阵表示矢量数据
* properties of high-dimensional vector spaces **高维向量空间的性质**
* basic notation for matrices 矩阵的基本符号
* view of matrices as linear maps 矩阵视图 - 线性映射
* how basic geometric transforms are implemented using matrices 使用**矩阵实现基本的几何变换**
* how matrix multiplication is defined and its algebraic properties 定义**矩阵乘法及其代数性质**
* the basic anatomy of matrices **矩阵的基本组成**

## Example: Text

string-弱结构，无法贡献于机器翻译系统

* 可以给文本片段**添加额外数学结构**
  * **将文本片段放置在向量空间(vector space)中**
  * **片段可以是单词、部分词或整个句子。这就是所谓的嵌入**算法Word2vec可以学习从字符串到高维向量(通常大于100D)的转换，只需观察大量的文本
* **虽然向量空间每个维度没有特定意义，但是嵌入embedding意味着语义semantics映射到空间关系上**

## Vector spaces

本课考虑向量是实数有序元组

* `[ x1，x2，... xn ] ，xi ∈ r`
* 向量固定维度`n`
  * **元组长度 length of the tuple**
* 可以假设向量中**每个元素**都为**与其他元素正交方向上的距离 a distance in an direction orthogonal**

🍊 例子 - 有需要记的概念

* **长度为3的向量（3维向量）**，可以用于表示笛卡尔坐标系中的空间位置
  * 每个向量有3个正交的测量量 3 **orthogonal measurements** for each vector
  * orthogonal - independent **正交即独立，即，=90°**
* 3D vector`[5,7,3]`
  * `ℝ^3`
  * 组成 `5*[1,0,0] + 7*[0,1,0] + 3*[0,0,1]`
  * 可看为**正交单位向量的加权和 weighted sum of orthogonal unit vectors**
  * 该向量空间有3个独立basis vectors, 因此为三维（向量长度也为3）
* `[1,0,0], [0,1,0], [0,0,1]`
  * **unit vector (basis vectors)**
  * 每个向量，长度为`1`
  * 都指向一个单独的方向(正交方向) orthogonal direction

🍊 向量表示

![](/static/2020-10-28-01-02-12.png)

* 用**小写加粗字母**表示向量

## Points in Space

### Notation

标记`ℝ^𝑛`

![](/static/2020-10-28-01-05-43.png)

* `ℝ`实数集
* `ℝ≥0`非负实数集合
* `ℝ^n`N 个实数的元组的集合 the set of tuples of exactly `n` real numbers
* `ℝ^n*m` n行m个元素的2维实数矩阵集合
* `(ℝ^𝑛,ℝ^𝑛)→ℝ` map：一对n维向量-实数的映射对
  * a map from a pair of n-dimensional vectors to a real number

## Vector spaces

![](/static/2020-10-28-01-16-47.png)

* 任何**规定了维数`n`的向量都位于【向量空间 `ℝ^𝑛`】**
  * 目前向量空间只考虑有限维度的实数向量空间（标准单位基本向量）【还有复数，无限维度空间】
  * **该向量属于，任何长度为`n`的，元素为实数的向量集合中**

🍊 且在该向量空间`ℝ^𝑛`下，规定了如下操作

* **标量乘法/标量积 `ax`** scalar multiplication
  * 对于任何标量`a`，都定义了`ax`（标量积？）
  * 对于实数向量，`ax=[ax1,ax2,...,axn]`元素缩放 elementwise scaling
  * ![](/static/2020-10-28-01-29-19.png)
* **向量加法 `x+y`** vector addition
  * `x+y`个向量， `x`& `y`维数相同
  * **实数向量**，`𝐱+𝐲=[𝑥1+𝑦1,𝑥2+𝑦2,…𝑥𝑑+𝑦𝑑]`元素和
  * ![](/static/2020-10-28-01-32-07.png)
* **norm `||𝐱||` 范式**
  * 测量向量长度
  * `ℝ𝑛→ℝ≥0`
  * ![](/static/2020-10-28-02-32-52.png)
* **向量内积 `⟨𝐱|𝐲⟩  or 𝐱∙𝐲`** inner product
  * **可以比较2个向量夹角 angle**
  * <font color="red">2个正交向量的向量内积为`0`，angle=90</font>
  * **实数向量的向量内积，即dot product点积** `𝐱∙𝐲=𝑥1𝑦1+𝑥2𝑦2+𝑥3𝑦3…𝑥𝑑𝑦𝑑`
  * ![](/static/2020-10-28-02-33-09.png)

🍬 向量间所有操作都在同一向量空间中定义

* 不同维度的向量，不属于同一向量空间，不能进行如上定义的操作

### topological & inner product spaces

拓扑&内积空间

![](/static/2020-10-28-02-41-33.png)

* 有了范式norm， 向量空间就是**拓扑向量空间**，意味着
  * 向量空间是连续的，且向量“紧靠在一起”（或向量周围有领域neighbourhood）
  * 对于向量内积，**向量空间即内积空间（内积集合？）inner product space**

🍊 空间中的向量点vector points、箭头指向，是从原点还是数字元组？

![](/static/2020-10-28-02-47-06.png)

* 数字元组？**或想象这些向量点在向量空间中**
* 向量表示数据，数据在向量空间中
  * vectors to represent data; data lies in space
* 矩阵由对数据的操作得来，矩阵扭曲向量空间
  * matrices to represent operations on data; matrices warp space

### Relation to arrays

与矩阵关系

* 实数向量可以用一维浮点数组来表示，在本系列的第一讲中，我们称之为“向量”
* 但是要小心，**表示和数学元素是不同的东西**，就像浮点数不是实数一样

![](/static/2020-10-28-03-04-57.png)
![](/static/2020-10-28-03-05-55.png)

标量积
![](/static/2020-10-28-03-06-21.png)
![](/static/2020-10-28-03-06-27.png)

![](/static/2020-10-28-03-08-18.png)
![](/static/2020-10-28-03-08-52.png)

* 向量相加
  * `x+y`
* 范式
  * `np.linalg.norm(x)`
* 点积，向量内积
  * `np.dot(x,y)`

### uses of vectors

向量使用

* **composed**
  * addition
* **compared**
  * norms/inner products
* **weighted**
  * scaling

🍬 向量可以对数据进行各种变换

* 因此vector->ndarray映射，可以更高效简洁操作

### Vector Data

数据集dataset，通常以**2D表格**存储

![](/static/2020-10-28-20-11-28.png)

* 可以看为向量列表 lists of vectors
* 每行 - 代表“observation”的vector
  * 每条观察记录stacked up组成2D矩阵
* 每列 - 跨多条观察值的一种元素

🍊

* 以上例子，每行可看为一个在向量空间`ℝ^4`中的向量
* 以上整个矩阵是同一个向量空间中的**向量序列**。这意味着我们可以对表格数据进行**几何描述 geometric**

### Geometric Operations

矢量最明显用途

* 表示二维/三维几何数据
* 游戏or3D渲染引擎中所有计算都由大规模重复**低维向量操作（2D,3D,4D）**组成

![](/static/2020-10-28-20-35-25.png)

图形化管道将所有东西(空间位置、表面法线方向、纹理坐标、颜色等)都处理为大量的矢量数组Graphical pipelines process everything (spatial position, surface normal direction, texture coordinates, colours, and so on) as large arrays of vectors

* 在 GPU 上进行图形编程主要涉及将**数据打包到低维向量数组**(在 CPU 上) ，然后使用**着色器语言在 GPU 上快速处理它们** Programming for graphics on GPUs largely involves packing data into a low-dimensional vector arrays (on the CPU) then processing them quickly on the GPU using a **shader language**

### Machine Learning Applications

机器学习很大程度上依赖向量表示

![](/static/2020-10-28-21-24-33.png)

* 将一些数据转换成**特征向量feature vectors**
  * 特征向量：向量空间中数据编码（如表格数据）
  * describe some data point that might be a vector representing a word image
* 创建一个函数，将**特征向量转换**为预测prediction(例如类标签)
  * 特征转换：处理raw data, 输出特征向量

🍊 最简单有效的机器学习算法之一

> k近邻算法：给定一个训练集，新输入实例。**在训练集中找到与该实例最邻近的k个实例**。
>
> 这**k个实例多数属于某个类**，就把该新输入实例分类到这个类中

* **k nearest neighbours**k近邻算法
  * 涉及data训练集，包含`xi,yi`对
    * 特征向量`xi`，标签`yi`
* 当一个新特征需要分类进行预测时，**计算该训练集中的 k 个最近的向量，使用范数计算距离**
  * 输出预测（把新输入归到多数类中）是这些 k 近邻实例中**出现次数最多的类标签**(k 在某种程度上是预设值; 对于许多问题，它可能在3-12左右)

### Image Compression

![](/static/2020-10-28-22-52-07.png)
![](/static/2020-10-28-22-54-56.png)

* 8x8 image patch could be unraveled to a 64-d vector
  * these vectors could be treated as elements of a vetor space

